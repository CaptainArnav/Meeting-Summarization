{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e97d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a947ce5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#only if GPU is available\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab36e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "def embed(input):\n",
    "  return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5aa5300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: Elephant\n",
      "Embedding size: 512\n",
      "Embedding: [0.008344488218426704, 0.00048081763088703156, 0.06595246493816376, ...]\n",
      "\n",
      "Message: I am a sentence for which I would like to get its embedding.\n",
      "Embedding size: 512\n",
      "Embedding: [0.0508086122572422, -0.01652432046830654, 0.015737777575850487, ...]\n",
      "\n",
      "Message: Universal Sentence Encoder embeddings also support short paragraphs. There is no hard limit on how long the paragraph is. Roughly, the longer the more 'diluted' the embedding will be.\n",
      "Embedding size: 512\n",
      "Embedding: [-0.0283326655626297, -0.05586216226220131, -0.012941446155309677, ...]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word = \"Elephant\"\n",
    "sentence = \"I am a sentence for which I would like to get its embedding.\"\n",
    "paragraph = (\n",
    "    \"Universal Sentence Encoder embeddings also support short paragraphs. \"\n",
    "    \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\n",
    "    \"the more 'diluted' the embedding will be.\")\n",
    "messages = [word, sentence, paragraph]\n",
    "\n",
    "# Reduce logging output.\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "message_embeddings = embed(messages)\n",
    "\n",
    "for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "  print(\"Message: {}\".format(messages[i]))\n",
    "  print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "  message_embedding_snippet = \", \".join((str(x) for x in message_embedding[:3]))\n",
    "  print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8901c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./split_0.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "'''\n",
    "results is a list of dictionaries with keys -> 'id', 'meeting', 'summary'\n",
    "turns is a 2d list consisting of speakers -> 'A', 'B', 'C' etc\n",
    "sentences is a 2d list consisting of corresponding turns' sentences \n",
    "summaries is a 2d list consisting of corresponding meeting's summary\n",
    "'''\n",
    "results = []\n",
    "sentences = []\n",
    "\n",
    "NUM_TURNS = 70\n",
    "\n",
    "for json_str in json_list:\n",
    "    results.append(json.loads(json_str))\n",
    "\n",
    "for result in results :\n",
    "    sentences_temp = []\n",
    "    for obj in result['meeting'][:NUM_TURNS] :\n",
    "        sentences_temp.append(' '.join(obj['utt']['word']))\n",
    "\n",
    "    sentences.append(sentences_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f9aa6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savez_compressed\n",
    "\n",
    "sentence_embeddings = []\n",
    "for sentence in sentences :\n",
    "    sentence_embeddings.append(np.array(embed(sentence)))\n",
    "\n",
    "# sentence_embeddings = np.array(sentence_embeddings).astype(float32)\n",
    "sentence_embeddings = np.array(sentence_embeddings).astype('float32')[:, :, :100]\n",
    "\n",
    "    \n",
    "\n",
    "savez_compressed('sentence_embeddings.npz', sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5ea031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 70, 100)\n"
     ]
    }
   ],
   "source": [
    "print(sentence_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d3b165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
