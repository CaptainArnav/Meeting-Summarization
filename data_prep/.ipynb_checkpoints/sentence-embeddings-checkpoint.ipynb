{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e97d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a947ce5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#only if GPU is available\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab36e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "def embed(input):\n",
    "  return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5aa5300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: Elephant\n",
      "Embedding size: 512\n",
      "Embedding: [0.008344488218426704, 0.00048081763088703156, 0.06595246493816376, ...]\n",
      "\n",
      "Message: I am a sentence for which I would like to get its embedding.\n",
      "Embedding size: 512\n",
      "Embedding: [0.0508086122572422, -0.016524313017725945, 0.015737785026431084, ...]\n",
      "\n",
      "Message: Universal Sentence Encoder embeddings also support short paragraphs. There is no hard limit on how long the paragraph is. Roughly, the longer the more 'diluted' the embedding will be.\n",
      "Embedding size: 512\n",
      "Embedding: [-0.028332678601145744, -0.0558621846139431, -0.012941466644406319, ...]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word = \"Elephant\"\n",
    "sentence = \"I am a sentence for which I would like to get its embedding.\"\n",
    "paragraph = (\n",
    "    \"Universal Sentence Encoder embeddings also support short paragraphs. \"\n",
    "    \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\n",
    "    \"the more 'diluted' the embedding will be.\")\n",
    "messages = [word, sentence, paragraph]\n",
    "\n",
    "# Reduce logging output.\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "message_embeddings = embed(messages)\n",
    "\n",
    "for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "  print(\"Message: {}\".format(messages[i]))\n",
    "  print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "  message_embedding_snippet = \", \".join((str(x) for x in message_embedding[:3]))\n",
    "  print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac01caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '../data/meetings'\n",
    "files = [join(dir_path, file_name) for file_name in listdir(dir_path)]\n",
    "\n",
    "sentences = []\n",
    "\n",
    "'''\n",
    "sentences is a 2d list consisting of corresponding turns' sentences \n",
    "'''\n",
    "\n",
    "NUM_TURNS = 70\n",
    "    \n",
    "for file in files :\n",
    "    with open(file, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "\n",
    "    for json_str in json_list:\n",
    "        res = json.loads(json_str)\n",
    "        sentences_temp = []\n",
    "        turns_temp = []\n",
    "        for obj in res['meeting'][:NUM_TURNS] :\n",
    "            turns_temp.append(ord(obj['speaker']) - 65) # convert letter to number i.e 'A' -> 0, 'B' -> 1\n",
    "            sentences_temp.append(' '.join(obj['utt']['word']))\n",
    "        if len(turns_temp) < NUM_TURNS :\n",
    "            continue\n",
    "        \n",
    "        sentences.append(sentences_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f9aa6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savez_compressed\n",
    "\n",
    "sentence_embeddings = []\n",
    "for sentence in sentences :\n",
    "    sentence_embeddings.append(np.array(embed(sentence)))\n",
    "\n",
    "# sentence_embeddings = np.array(sentence_embeddings).astype(float32)\n",
    "sentence_embeddings = np.array(sentence_embeddings).astype('float32')[:, :, :100]\n",
    "\n",
    "    \n",
    "\n",
    "savez_compressed('../data/obj/sentence_embeddings.npz', sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5ea031b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 70, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
