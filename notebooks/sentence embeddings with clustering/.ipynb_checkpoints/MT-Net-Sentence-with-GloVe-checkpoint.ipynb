{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7270526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d75ba085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only if GPU is available\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e79782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "meetings = np.load('../../data/obj/meetings.npz')['arr_0'] # (num_meetings, num_turns, seq_len)\n",
    "summary = np.load('../../data/obj/summary.npz')['arr_0'] # (num_meetings, summary_len)\n",
    "\n",
    "turns = np.load('../../data/obj/turns.npz')['arr_0'] # (num_meetings, num_turns)\n",
    "role_vector = np.load('../../data/obj/role_vector.npz')['arr_0'] # (num_roles, MAX_LENGTH_BIN = 3)\n",
    "\n",
    "sentence_embeddings = np.load('../../data/obj/sentence_embeddings.npz')['arr_0'] # (num_meetings, num_turns, sentence_embedding_dim)\n",
    "\n",
    "with open('../../data/obj/tokenizer.pickle', 'rb') as file:\n",
    "    tokenizer = pickle.load(file)\n",
    "    \n",
    "vocabulary_size = len(tokenizer.word_index) + 1\n",
    "word_embedding_dimension = 100\n",
    "sentence_embedding_dimension = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c431afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 70, 100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meetings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7364423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(file_path) :\n",
    "    '''\n",
    "    parameters : file_path - path of file where embeddings are stored (eg: '<path>/glove.6B/glove.6B.100d.txt')\n",
    "    load the words and their respective embeddings from the GloVe file and set up a dictionary mapping \n",
    "    of words and their corresponding embeddings (embeddings will be stored in a numpy array of shape (d, ))\n",
    "    returns : embedding_dict - dictionary mapping of {word:embedding}\n",
    "    ''' \n",
    "    \n",
    "    embedding_dict = {}\n",
    "    file = open(file_path)\n",
    "    for line in file :\n",
    "        data = line.split(\" \")\n",
    "        word = data[0]\n",
    "        embedding = np.asarray(data[1:], dtype='float32')\n",
    "        embedding_dict[word] = embedding\n",
    "    file.close()\n",
    "    return embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd79ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_embedding_matrix(embedding_dict, vocabulary, embedding_dimension) :\n",
    "    '''\n",
    "    parameters : embedding dict - dictionary mapping of {word:embedding} \n",
    "                 vocabulary - list of words in the training dataset\n",
    "                 embedding_dimension - dimension of word embeddings used in the model\n",
    "    initialises the embedding matrix with the ith row corresponding to the embedding of the ith word in the vocabulary\n",
    "    dimension of the embedding depends on the \n",
    "    returns : embedding_matrix of shape (n, d) where n is the number of words in the vocabulary and d is the \n",
    "              dimension of the embeddings\n",
    "    '''\n",
    "    \n",
    "    embedding_matrix = np.random.normal(0, 0.1, (len(vocabulary) + 1, embedding_dimension))\n",
    "    for i, word in enumerate(vocabulary) :\n",
    "        if word in embedding_dict.keys() :\n",
    "            word_embedding = embedding_dict[word]\n",
    "            embedding_matrix[i] = word_embedding\n",
    "    return embedding_matrix\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71eb79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rand_embedding_layer(vocabulary_size, embedding_dimension) :\n",
    "    '''\n",
    "    parameters : vocabulary_size - size of vocabulary used\n",
    "                 embedding_dimension - integer which indicated the dimension of the word embeddings\n",
    "                 max_length - maximum length of the input to the model(eg : maximum length of an input sentence)\n",
    "    creates the embedding layer with trainable set to true so that weights cannot be changed during training.\n",
    "    Weights of the embedding layer follow normal distribution with mean=0, stddev=0.1\n",
    "    returns : embedding_layer \n",
    "    '''\n",
    "    \n",
    "    embedding_matrix = np.random.normal(0, 0.1, (vocabulary_size, embedding_dimension))\n",
    "    embedding_layer = layers.Embedding(input_dim=vocabulary_size,\n",
    "                                      output_dim=embedding_dimension,\n",
    "                                      weights=[embedding_matrix],\n",
    "                                      trainable=True,\n",
    "                                      name='embedding_rand')\n",
    "    return embedding_layer\n",
    "\n",
    "\n",
    "def get_static_embedding_layer(embedding_matrix) :\n",
    "    '''\n",
    "    parameters : embedding_matrix - numpy array of shape (n, d) used to set the weights of the embedding layer\n",
    "                 max_length - maximum length of the input to the model(eg : maximum length of an input sentence)\n",
    "    creates the embedding layer and sets its weights with trainable set to false \n",
    "    so that weights cannot be changed during training\n",
    "    returns : embedding_layer \n",
    "    '''\n",
    "    \n",
    "    embedding_layer = layers.Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                                      output_dim=embedding_matrix.shape[1],\n",
    "                                      weights=[embedding_matrix],\n",
    "                                      trainable=False,\n",
    "                                      name='embedding_static')\n",
    "    return embedding_layer\n",
    "\n",
    "\n",
    "def get_dynamic_embedding_layer(embedding_matrix) :\n",
    "    '''\n",
    "    parameters : embedding_matrix - numpy array of shape (n, d) used to set the weights of the embedding layer\n",
    "                 max_length - maximum length of the input to the model(eg : maximum length of an input sentence)\n",
    "    creates the embedding layer and sets its weights with trainable set to true \n",
    "    so that weights can be changed or fine-tuned during training\n",
    "    returns : embedding_layer \n",
    "    '''\n",
    "    \n",
    "    embedding_layer = layers.Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                                      output_dim=embedding_matrix.shape[1],\n",
    "                                      weights=[embedding_matrix],\n",
    "                                      trainable=True,\n",
    "                                      name='embedding_dynamic')\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53e7cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer) :\n",
    "    def __init__(self) :\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        \n",
    "    def call(self, word_embeddings) :\n",
    "        '''\n",
    "        parameters : word_embeddings - tensor of shape (num_turns, seq_len, embed_dim)\n",
    "        returns : embeddings_with_position - tensor of shape (num_turns, seq_len, embed_dim)\n",
    "        '''\n",
    "        positional_embeddings = np.zeros((word_embeddings.shape[1], word_embeddings.shape[2]))\n",
    "        for i  in range(positional_embeddings.shape[0]) :\n",
    "            if i % 2 == 0 :\n",
    "                positional_embeddings[i] = np.array([np.sin(i/(1000 ** (2 * j / positional_embeddings.shape[1]))) for j in range(positional_embeddings.shape[1])])\n",
    "            else :\n",
    "                positional_embeddings[i] = np.array([np.cos(i/(1000 ** (2 * j / positional_embeddings.shape[1]))) for j in range(positional_embeddings.shape[1])])\n",
    "        \n",
    "        positional_embeddings = np.repeat(positional_embeddings[np.newaxis, :, :], word_embeddings.shape[0], axis=0)\n",
    "        \n",
    "        embeddings_with_position = positional_embeddings + word_embeddings\n",
    "        return embeddings_with_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87ff4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(layers.Layer) :\n",
    "    def __init__(self, is_mask=False) :\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.is_mask = is_mask\n",
    "        \n",
    "    def call(self, query, key, value) :\n",
    "        '''\n",
    "        parameters : query - tensor of shape (num_turns, num_heads, seq_len_q, dim) \n",
    "                     key - tensor of shape (num_turns, num_heads, seq_len_k, dim) \n",
    "                     value - tensor of shape (num_turns, num_heads, seq_len_v, dim) \n",
    "                     **seq_len_k == seq_len_v\n",
    "        returns : attention - tensor of shape (num_turns, num_heads, seq_len, dim) \n",
    "        '''\n",
    "        # (num_turns, num_heads, seq_len_q, seq_len_k)\n",
    "        pre_attention = tf.linalg.matmul(query, key, transpose_b=True) / np.sqrt(key.shape[1])\n",
    "\n",
    "        if self.is_mask is True :\n",
    "            mask = np.zeros((pre_attention.shape[-2], pre_attention.shape[-1]))\n",
    "            mask.fill(-1e10)            \n",
    "            mask = np.triu(mask, k=1)\n",
    "            pre_attention = tf.math.multiply(pre_attention, mask)\n",
    "            \n",
    "        attention_weights = tf.nn.softmax(pre_attention, axis=-1)\n",
    "        \n",
    "        # (num_turns, num_heads, seq_len_q, dim)\n",
    "        attention = tf.linalg.matmul(attention_weights, value)\n",
    "        \n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "224cd447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(layers.Layer) :\n",
    "    def __init__(self, embedding_dimension, num_heads, is_mask=False) :\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.dim = self.embedding_dimension // self.num_heads\n",
    "        self.is_mask = is_mask\n",
    "        \n",
    "        assert(self.dim * self.num_heads == self.embedding_dimension), \"embedding_dimension should be divisible by num_heads.\"\n",
    "\n",
    "        self.query_layer = layers.Dense(self.embedding_dimension)\n",
    "        self.key_layer = layers.Dense(self.embedding_dimension)\n",
    "        self.value_layer = layers.Dense(self.embedding_dimension)\n",
    "        \n",
    "        self.scaled_dot_product_attention = ScaledDotProductAttention(is_mask=self.is_mask)\n",
    "        \n",
    "        self.linear_layer = layers.Dense(self.embedding_dimension)\n",
    "    \n",
    "    \n",
    "    def split_heads(self, input_tensor) :\n",
    "        '''\n",
    "        parameters : input_tensor - tensor of shape (num_turns, seq_len, embedding_dimension)\n",
    "        returns : input_tensor - resize tensor of shape (num_turns, num_heads, seq_len, dim)\n",
    "        '''\n",
    "        input_tensor = tf.reshape(input_tensor, (input_tensor.shape[0], -1, self.num_heads, self.dim))\n",
    "        return tf.transpose(input_tensor, [0,2,1,3])\n",
    "        \n",
    "        \n",
    "    def call(self, query, key, value) :\n",
    "        '''\n",
    "        parameters : query - tensor of shape (num_turns, seq_len, embedding_dimension)\n",
    "                     key - tensor of shape (num_turns, seq_len, embedding_dimension)\n",
    "                     value - tensor of shape (num_turns, seq_len, embedding_dimension)\n",
    "        returns : res - tensor of shape (num_turns, seq_len, embedding_dimension)\n",
    "        '''\n",
    "\n",
    "        query = self.query_layer(query)\n",
    "        key = self.key_layer(key)\n",
    "        value = self.value_layer(value)\n",
    "        \n",
    "        query = self.split_heads(query)\n",
    "        key = self.split_heads(key)\n",
    "        value = self.split_heads(value)\n",
    "        \n",
    "        attention = self.scaled_dot_product_attention(query, key, value) # (num_turns, num_heads, seq_len, dim)\n",
    "        \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) # (num_turns, seq_len, num_heads, dim)\n",
    "        concat_attention = tf.reshape(attention, (attention.shape[0], -1, self.embedding_dimension)) # (num_turns, seq_len, embedding_dimension)\n",
    "        \n",
    "        res = self.linear_layer(concat_attention) # (num_turns, seq_len, embedding_dimension)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55f70467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddandNorm(layers.Layer) :\n",
    "    def __init__(self) :\n",
    "        super(AddandNorm, self).__init__()\n",
    "        self.layer_norm = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "    def call(self, input_tensor, skip_connection) :\n",
    "        '''\n",
    "        parameters : input_tensor - tensor of shape (num_turns, seq_len, embedding_dimension)\n",
    "                     skip_connection - tensor of shape (num_turns, seq_len, embedding_dimension)\n",
    "        returns : res - normalized tensor of shape (num_turns, seq_len, embedding_dimension)\n",
    "        '''\n",
    "        res = input_tensor + skip_connection\n",
    "        res = self.layer_norm(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3681aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(layers.Layer) :\n",
    "    def __init__(self, hidden_dim, output_dim) :\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.layer_1 = layers.Dense(hidden_dim, activation='relu')\n",
    "        self.layer_2 = layers.Dense(output_dim)\n",
    "        \n",
    "    def call(self, input_tensor) :\n",
    "        '''\n",
    "        parameters : input_tensor - tensor of shape (num_turns, seq_len, embedding_dimension)\n",
    "        returns : input_tensor - tensor of shape (num_turns, seq_len, embedding_dimension)\n",
    "        '''\n",
    "        res = self.layer_1(input_tensor)\n",
    "        res = self.layer_2(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61b17581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_role_vector(x, role_vector, turn_seq) :\n",
    "    '''\n",
    "    parameters : x - tensor of shape (1, num_turns, embed_dim)\n",
    "                 role_vector - tensor of shape (num_roles, role_vector_size)\n",
    "                 turn_seq - np array of shape (num_turns, ) representing the sequence of turns in a meeting\n",
    "    returns : concat_vector - concatenated vector of sentence embedding and role_vector for each turn\n",
    "                              of shape (1, num_turns, embed_dim + role_vector_size)\n",
    "    '''\n",
    "\n",
    "\n",
    "#     unpacked_turn_seq = tf.unstack(turn_seq)\n",
    "#     unpacked_turn_seq = turn_seq.numpy()\n",
    "    \n",
    "    role = tf.expand_dims(tf.convert_to_tensor([role_vector[j] for j in turn_seq]), 0)\n",
    "    turn_with_role = tf.concat([x, role], axis=2) # (1, num_turns, embed_dim + role_vector_size)\n",
    "    \n",
    "    return turn_with_role\n",
    "\n",
    "# x = tf.random.uniform((1, 10, 512))\n",
    "# role_vector = tf.random.uniform((2, 32))\n",
    "# turn_seq = [0,1,1,0,1,0,1,0,1,0]\n",
    "\n",
    "# print(concat_role_vector(x, role_vector, turn_seq).shape)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0207382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33 34 64 66 67]\n"
     ]
    }
   ],
   "source": [
    "def get_clusters(num_clusters, data) :\n",
    "    '''\n",
    "    parameters : num_clusters - number of clusters for K-means clustering\n",
    "                 data - tensor of shape (num_turns, sent_embed_dim + role_vector_size)\n",
    "    returns : closest_data - np array of shape (num_clusters, ) containing indices of top 'num_cluster' sentences\n",
    "    '''\n",
    "    \n",
    "    num_clusters = num_clusters\n",
    "\n",
    "    m_km = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    m_km = m_km.fit(data.numpy())\n",
    "    m_clusters = m_km.labels_.tolist()\n",
    "\n",
    "    centers = np.array(m_km.cluster_centers_)\n",
    "\n",
    "    closest_data = []\n",
    "    for i in range(num_clusters):\n",
    "        center_vec = centers[i]\n",
    "        data_idx_within_i_cluster = [ idx for idx, clu_num in enumerate(m_clusters) if clu_num == i ]\n",
    "\n",
    "        one_cluster_tf_matrix = np.zeros( (  len(data_idx_within_i_cluster) , centers.shape[1] ) )\n",
    "        for row_num, data_idx in enumerate(data_idx_within_i_cluster):\n",
    "            one_row = data[data_idx]\n",
    "            one_cluster_tf_matrix[row_num] = one_row\n",
    "\n",
    "        closest, _ = pairwise_distances_argmin_min(center_vec.reshape(1, -1), one_cluster_tf_matrix)\n",
    "        closest_idx_in_one_cluster_tf_matrix = closest[0]\n",
    "        closest_data_row_num = data_idx_within_i_cluster[closest_idx_in_one_cluster_tf_matrix]\n",
    "\n",
    "        closest_data.append(closest_data_row_num)\n",
    "    return np.sort(np.array(closest_data))\n",
    "\n",
    "input_tensor = tf.random.uniform((1, 70, 132), dtype=tf.float64, minval=0, maxval=200)\n",
    "print(get_clusters(5, input_tensor[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b50973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(layers.Layer) :\n",
    "    def __init__(self, embedding_dimension, num_heads) :\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.multi_head_attention = MultiHeadAttention(embedding_dimension, num_heads)\n",
    "        self.add_and_norm_1 = AddandNorm()\n",
    "        self.feed_forward = FeedForward(200, embedding_dimension)\n",
    "        self.add_and_norm_2 = AddandNorm()\n",
    "        \n",
    "    def call(self, input_tensor) :\n",
    "        '''\n",
    "        parameters : input_tensor - tensor of shape (num_turns, seq_len, embedding_dimension)\n",
    "        returns : input_tensor - tensor of shape (num_turns, seq_len, embedding_dimension)\n",
    "        '''\n",
    "        res = self.multi_head_attention(input_tensor, input_tensor, input_tensor)\n",
    "        res_skip = self.add_and_norm_1(res, input_tensor)\n",
    "        res = self.feed_forward(res_skip)\n",
    "        res = self.add_and_norm_2(res, res_skip)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "64bb7768",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(layers.Layer) :\n",
    "    def __init__(self, embedding_dimension, num_heads) :\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.masked_multi_head_attention = MultiHeadAttention(embedding_dimension, num_heads, is_mask=True)\n",
    "        self.add_and_norm_1 = AddandNorm()\n",
    "        \n",
    "        self.multi_head_attention_1 = MultiHeadAttention(embedding_dimension, num_heads)\n",
    "        self.add_and_norm_2 = AddandNorm()\n",
    "        \n",
    "        self.multi_head_attention_2 = MultiHeadAttention(embedding_dimension, num_heads)\n",
    "        self.add_and_norm_3 = AddandNorm()\n",
    "        \n",
    "        self.feed_forward = FeedForward(200, embedding_dimension)\n",
    "        self.add_and_norm_4 = AddandNorm()\n",
    "        \n",
    "    def call(self, input_tensor, sentence_level_encoder_output, turn_level_encoder_output) :\n",
    "        res = self.masked_multi_head_attention(input_tensor, input_tensor, input_tensor)\n",
    "        res_skip = self.add_and_norm_1(res, input_tensor)\n",
    "        \n",
    "        res = self.multi_head_attention_1(res_skip, sentence_level_encoder_output, sentence_level_encoder_output)\n",
    "        res_skip = self.add_and_norm_2(res, res_skip)\n",
    "        \n",
    "        res = self.multi_head_attention_2(res_skip, turn_level_encoder_output, turn_level_encoder_output)\n",
    "        res_skip = self.add_and_norm_3(res, res_skip)\n",
    "        \n",
    "        res = self.feed_forward(res_skip)\n",
    "        res = self.add_and_norm_4(res, res_skip)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "687cba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer) :\n",
    "    def __init__(self, \n",
    "                 num_blocks, \n",
    "                 embedding_dimension, \n",
    "                 num_heads) :\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_blocks = num_blocks\n",
    "        \n",
    "        self.encoder_blocks = [EncoderBlock(embedding_dimension, num_heads) for _ in range(num_blocks)]\n",
    "        \n",
    "    def call(self, input_tensor) :\n",
    "        '''\n",
    "        parameters : input_tensor : tensor of shape (num_turns, seq_len, embed_dim) / (num_turns, 1, embed_dim + role_vector_size)\n",
    "        returns : x - tensor of shape (num_turns, seq_len, embed_dim) / (num_turns, 1, embed_dim + role_vector_size)\n",
    "        '''\n",
    "        x = input_tensor\n",
    "        \n",
    "        for i in range(self.num_blocks) :\n",
    "            x = self.encoder_blocks[i](x) # (num_turns, seq_len, embed_dim) \n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1dabd9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 5, 100])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_blocks=2, \n",
    "                         embedding_dimension=100, \n",
    "                         num_heads=10)\n",
    "\n",
    "input_tensor = tf.random.uniform((10, 5, 100), dtype=tf.float64, minval=0, maxval=200)\n",
    "\n",
    "output_tensor = sample_encoder(input_tensor)\n",
    "\n",
    "output_tensor.shape  # (num_turns, seq_len, embed_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02496faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer) :\n",
    "    def __init__(self, \n",
    "                 num_blocks, \n",
    "                 embedding_dimension, \n",
    "                 num_heads) :\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        self.num_blocks = num_blocks\n",
    "        \n",
    "        self.decoder_blocks = [DecoderBlock(embedding_dimension, num_heads) for _ in range(num_blocks)]\n",
    "        \n",
    "    def call(self, input_tensor, word_level_encoder_output, turn_level_encoder_output) :\n",
    "        '''\n",
    "        parameters : input_tensor : tensor of shape (batch_size=1, target_seq_len, embed_dim)\n",
    "        returns : x - tensor of shape (batch_size=1, target_seq_len, embed_dim) \n",
    "        '''\n",
    "        x = input_tensor\n",
    "        for i in range(self.num_blocks) :\n",
    "            x = self.decoder_blocks[i](x, word_level_encoder_output, turn_level_encoder_output)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2bc7b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 7, 100])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_blocks=2, \n",
    "                         embedding_dimension=100, \n",
    "                         num_heads=10)\n",
    "\n",
    "input_tensor = tf.random.uniform((1, 7, 100), dtype=tf.float64, minval=0, maxval=200)\n",
    "word_level_tensor = tf.random.uniform((10, 5, 100), dtype=tf.float64, minval=0, maxval=200)\n",
    "turn_level_tensor = tf.random.uniform((10, 1, 132), dtype=tf.float64, minval=0, maxval=200)\n",
    "\n",
    "output_tensor = sample_decoder(input_tensor, word_level_tensor, turn_level_tensor)\n",
    "\n",
    "output_tensor.shape  # (batch_size=1, target_seq_len, embed_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53af8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTNet(tf.keras.Model) :\n",
    "    def __init__(self, \n",
    "                 num_blocks, \n",
    "                 word_embedding_dimension,\n",
    "                 sentence_embedding_dimension,\n",
    "                 num_heads_word, \n",
    "                 num_heads_dec, \n",
    "                 vocabulary_size,\n",
    "                 embedding_matrix,\n",
    "                 role_vector_size, \n",
    "                 init_role_vector, \n",
    "                 num_clusters=50,\n",
    "                 mode='static') :\n",
    "        \n",
    "        super(MTNet, self).__init__()\n",
    "        \n",
    "        self.init_role_vector = init_role_vector\n",
    "        self.num_clusters = num_clusters\n",
    "        \n",
    "        self.embedding_layer = None\n",
    "        if mode == 'static' :\n",
    "            self.embedding_layer = get_static_embedding_layer(embedding_matrix)\n",
    "        elif mode == 'dynamic' :\n",
    "            self.embedding_layer = get_dynamic_embedding_layer(embedding_matrix)\n",
    "        elif mode == 'rand' :\n",
    "            self.embedding_layer = get_rand_embedding_layer(vocabulary_size, word_embedding_dimension) \n",
    "            \n",
    "        self.positional_embedding_layer = PositionalEmbedding()\n",
    "                                                            \n",
    "        \n",
    "        self.encoder = Encoder(num_blocks, \n",
    "                                          sentence_embedding_dimension + role_vector_size, \n",
    "                                          num_heads_word)\n",
    "        \n",
    "        self.role_vector = layers.Dense(role_vector_size)\n",
    "        \n",
    "        self.decoder = Decoder(num_blocks, \n",
    "                               word_embedding_dimension, \n",
    "                               num_heads_dec)\n",
    "        \n",
    "        self.fully_connected_layer = layers.Dense(vocabulary_size)\n",
    "        \n",
    "    def call(self, sentence_embedding, input_tensor, target_tensor, turn_seq) :\n",
    "\n",
    "        sentence_embedding_input = self.positional_embedding_layer(sentence_embedding) # (1, num_turns, sent_embed_dim)\n",
    "        \n",
    "        input_role_vector = self.role_vector(self.init_role_vector) # (num_roles, role_vector_size)\n",
    "\n",
    "        # (1, num_turns, sent_embed_dim + role_vector_size)\n",
    "        x1_concat = concat_role_vector(sentence_embedding_input, input_role_vector, turn_seq) \n",
    "        \n",
    "        x1 = self.encoder(x1_concat) # (1, num_turns, sent_embed_dim + role_vector_size)\n",
    "\n",
    "        #for a single meeting or batch\n",
    "        closest_points_index = get_clusters(self.num_clusters, x1[0]) # (num_turns)\n",
    "        \n",
    "        clustered_turns = np.zeros((self.num_clusters, input_tensor.shape[-1])) # (num_clusters, seq_len)\n",
    "\n",
    "        for index, cluster_point in enumerate(closest_points_index) :\n",
    "            clustered_turns[index] = input_tensor[0][cluster_point]\n",
    "        \n",
    "        x2 = self.embedding_layer(clustered_turns) # (num_clusters, seq_len, word_embed_dim)\n",
    "        x2 = tf.reshape(x2, [1, -1, x2.shape[-1]]) # (1, num_clusters * seq_len, word_embed_dim)\n",
    "        \n",
    "        target_x = self.embedding_layer(target_tensor) # (batch_size=1, target_seq_len, word_embed_dim)\n",
    "        target_x = self.positional_embedding_layer(target_x) # (batch_size=1, target_seq_len, word_embed_dim)\n",
    "        \n",
    "        x = self.decoder(target_x, x1, x2) # (batch_size=1, target_seq_len, embed_dim)\n",
    "        x = self.fully_connected_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "050436bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 3, 5061])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_role_vector = tf.random.uniform((2, 2))\n",
    "turn_seq = np.array([0,1,1,0,1,0,1,0,1,0])\n",
    "temp_embedding_matrix = np.random.normal(0, 0.1, (vocabulary_size, word_embedding_dimension))\n",
    "\n",
    "sample_mtnet = MTNet(num_blocks=2, \n",
    "                     word_embedding_dimension=100, \n",
    "                     sentence_embedding_dimension=100,\n",
    "                     num_heads_word=11, \n",
    "                     num_heads_dec=10, \n",
    "                     vocabulary_size=vocabulary_size,\n",
    "                     role_vector_size=32, \n",
    "                     init_role_vector=trial_role_vector, \n",
    "                     embedding_matrix=temp_embedding_matrix,\n",
    "                     num_clusters=5,\n",
    "                     mode='static')\n",
    "\n",
    "sentence_embedding = tf.random.uniform((1, 10, 100), dtype=tf.float64, minval=0, maxval=200)\n",
    "temp_input = tf.random.uniform((1, 10, 5), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((1, 3), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out = sample_mtnet(sentence_embedding, temp_input, temp_target, turn_seq)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b9c5c694",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((sentence_embeddings, meetings, summary))\n",
    "dataset = dataset.batch(1)\n",
    "\n",
    "# meetings1, summary1= next(iter(dataset))\n",
    "# sentence_embeddings.shape, meetings1.shape, summary1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a804102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Glove embeddings(100 dimensional) and convert it into a dictionary with mapping {word:embedding}\n",
    "\n",
    "file_path = '../../../GloVe/glove.6B/glove.6B.100d.txt'\n",
    "embedding_dict = load_embeddings(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "99f2ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = tokenizer.word_index.keys()\n",
    "embedding_matrix = set_embedding_matrix(embedding_dict, vocabulary, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1dba00c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.1, beta_1=0.9, beta_2=0.98,epsilon=1e-9)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6dd7cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d1f448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7de07fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtnet = MTNet(num_blocks=2, \n",
    "             word_embedding_dimension=100,\n",
    "             sentence_embedding_dimension =100,\n",
    "             num_heads_word=11, \n",
    "             num_heads_dec=10, \n",
    "             vocabulary_size=vocabulary_size,  \n",
    "             embedding_matrix=embedding_matrix,\n",
    "             role_vector_size=32, \n",
    "             init_role_vector=role_vector,\n",
    "             num_clusters=5,\n",
    "             mode='static')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a35d7d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(1, 70, 100), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(1, 70, 100), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(1, 100), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(70), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(sentence_embeddings, input_tensor, target_tensor, turn_seq):\n",
    "        \n",
    "    target_inp = target_tensor[:, :-1]\n",
    "    target_real = target_tensor[:, 1:]\n",
    "\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = mtnet(sentence_embeddings, input_tensor, target_inp, turn_seq)\n",
    "        loss = loss_function(target_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, mtnet.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, mtnet.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(target_real, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e15bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test input\n",
    "# sentence_embeddings = np.array(tf.random.uniform((1, 10, 100), dtype=tf.float32, minval=0, maxval=200))\n",
    "# input_tensor = np.array(tf.random.uniform((1, 10, 9), dtype=tf.int64, minval=0, maxval=200))\n",
    "# target_tensor = np.array(tf.random.uniform((1, 6), dtype=tf.int64, minval=0, maxval=200))\n",
    "# input_role_vector = np.array(tf.random.uniform((2, 2)))\n",
    "# turn_seq = [0,1,1,0,1,0,1,0,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9500e846",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 3.6331 Accuracy 0.0909\n",
      "Epoch 1 Batch 5 Loss 3.6331 Accuracy 0.0909\n",
      "Epoch 1 Batch 10 Loss 3.6331 Accuracy 0.0909\n",
      "Epoch 1 Batch 15 Loss 3.6331 Accuracy 0.0909\n",
      "Epoch 1 Batch 20 Loss 3.6330 Accuracy 0.0909\n",
      "Epoch 1 Batch 25 Loss 3.6330 Accuracy 0.0909\n",
      "Epoch 1 Batch 30 Loss 3.6330 Accuracy 0.0909\n",
      "Epoch 1 Batch 35 Loss 3.6330 Accuracy 0.0909\n",
      "Epoch 1 Batch 40 Loss 3.6330 Accuracy 0.0909\n",
      "Epoch 1 Batch 45 Loss 3.6330 Accuracy 0.0909\n",
      "Epoch 1 Batch 50 Loss 3.6330 Accuracy 0.0909\n",
      "Epoch 1 Batch 55 Loss 3.6331 Accuracy 0.0909\n",
      "Epoch 1 Batch 60 Loss 3.6343 Accuracy 0.0909\n",
      "Epoch 1 Batch 65 Loss 3.6349 Accuracy 0.0909\n",
      "Epoch 1 Batch 70 Loss 3.6352 Accuracy 0.0909\n",
      "Epoch 1 Batch 75 Loss 3.6353 Accuracy 0.0909\n",
      "Epoch 1 Batch 80 Loss 3.6356 Accuracy 0.0909\n",
      "Epoch 1 Batch 85 Loss 3.6357 Accuracy 0.0909\n",
      "Epoch 1 Batch 90 Loss 3.6357 Accuracy 0.0909\n",
      "Epoch 1 Loss 3.6357 Accuracy 0.0909\n",
      "Time taken for 1 epoch: 13.60 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 3.6355 Accuracy 0.0909\n",
      "Epoch 2 Batch 5 Loss 3.6344 Accuracy 0.0909\n",
      "Epoch 2 Batch 10 Loss 3.6362 Accuracy 0.0909\n",
      "Epoch 2 Batch 15 Loss 3.6358 Accuracy 0.0909\n",
      "Epoch 2 Batch 20 Loss 3.6363 Accuracy 0.0909\n",
      "Epoch 2 Batch 25 Loss 3.6365 Accuracy 0.0909\n",
      "Epoch 2 Batch 30 Loss 3.6364 Accuracy 0.0909\n",
      "Epoch 2 Batch 35 Loss 3.6363 Accuracy 0.0909\n",
      "Epoch 2 Batch 40 Loss 3.6362 Accuracy 0.0909\n",
      "Epoch 2 Batch 45 Loss 3.6359 Accuracy 0.0909\n",
      "Epoch 2 Batch 50 Loss 3.6369 Accuracy 0.0909\n",
      "Epoch 2 Batch 55 Loss 3.6391 Accuracy 0.0902\n",
      "Epoch 2 Batch 60 Loss 3.6398 Accuracy 0.0902\n",
      "Epoch 2 Batch 65 Loss 3.6399 Accuracy 0.0903\n",
      "Epoch 2 Batch 70 Loss 3.6398 Accuracy 0.0903\n",
      "Epoch 2 Batch 75 Loss 3.6396 Accuracy 0.0904\n",
      "Epoch 2 Batch 80 Loss 3.6393 Accuracy 0.0904\n",
      "Epoch 2 Batch 85 Loss 3.6390 Accuracy 0.0904\n",
      "Epoch 2 Batch 90 Loss 3.6387 Accuracy 0.0905\n",
      "Epoch 2 Loss 3.6386 Accuracy 0.0905\n",
      "Time taken for 1 epoch: 13.83 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 3.6333 Accuracy 0.0909\n",
      "Epoch 3 Batch 5 Loss 3.6336 Accuracy 0.0909\n",
      "Epoch 3 Batch 10 Loss 3.6338 Accuracy 0.0909\n",
      "Epoch 3 Batch 15 Loss 3.6345 Accuracy 0.0909\n",
      "Epoch 3 Batch 20 Loss 3.6344 Accuracy 0.0909\n",
      "Epoch 3 Batch 25 Loss 3.6344 Accuracy 0.0909\n",
      "Epoch 3 Batch 30 Loss 3.6342 Accuracy 0.0909\n",
      "Epoch 3 Batch 35 Loss 3.6342 Accuracy 0.0909\n",
      "Epoch 3 Batch 40 Loss 3.6342 Accuracy 0.0909\n",
      "Epoch 3 Batch 45 Loss 3.6341 Accuracy 0.0909\n",
      "Epoch 3 Batch 50 Loss 3.6341 Accuracy 0.0909\n",
      "Epoch 3 Batch 55 Loss 3.6341 Accuracy 0.0909\n",
      "Epoch 3 Batch 60 Loss 3.6342 Accuracy 0.0909\n",
      "Epoch 3 Batch 65 Loss 3.6345 Accuracy 0.0909\n",
      "Epoch 3 Batch 70 Loss 3.6346 Accuracy 0.0909\n",
      "Epoch 3 Batch 75 Loss 3.6346 Accuracy 0.0909\n",
      "Epoch 3 Batch 80 Loss 3.6346 Accuracy 0.0909\n",
      "Epoch 3 Batch 85 Loss 3.6345 Accuracy 0.0909\n",
      "Epoch 3 Batch 90 Loss 3.6345 Accuracy 0.0909\n",
      "Epoch 3 Loss 3.6351 Accuracy 0.0909\n",
      "Time taken for 1 epoch: 14.03 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 3.6387 Accuracy 0.0909\n",
      "Epoch 4 Batch 5 Loss 3.6405 Accuracy 0.0909\n",
      "Epoch 4 Batch 10 Loss 3.6387 Accuracy 0.0909\n",
      "Epoch 4 Batch 15 Loss 3.6376 Accuracy 0.0909\n",
      "Epoch 4 Batch 20 Loss 3.6368 Accuracy 0.0909\n",
      "Epoch 4 Batch 25 Loss 3.6362 Accuracy 0.0909\n",
      "Epoch 4 Batch 30 Loss 3.6358 Accuracy 0.0909\n",
      "Epoch 4 Batch 35 Loss 3.6354 Accuracy 0.0909\n",
      "Epoch 4 Batch 40 Loss 3.6351 Accuracy 0.0909\n",
      "Epoch 4 Batch 45 Loss 3.6355 Accuracy 0.0909\n",
      "Epoch 4 Batch 50 Loss 3.6361 Accuracy 0.0909\n",
      "Epoch 4 Batch 55 Loss 3.6361 Accuracy 0.0909\n",
      "Epoch 4 Batch 60 Loss 3.6360 Accuracy 0.0909\n",
      "Epoch 4 Batch 65 Loss 3.6359 Accuracy 0.0909\n",
      "Epoch 4 Batch 70 Loss 3.6358 Accuracy 0.0909\n",
      "Epoch 4 Batch 75 Loss 3.6356 Accuracy 0.0909\n",
      "Epoch 4 Batch 80 Loss 3.6355 Accuracy 0.0909\n",
      "Epoch 4 Batch 85 Loss 3.6353 Accuracy 0.0909\n",
      "Epoch 4 Batch 90 Loss 3.6352 Accuracy 0.0909\n",
      "Epoch 4 Loss 3.6351 Accuracy 0.0909\n",
      "Time taken for 1 epoch: 13.76 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 3.6330 Accuracy 0.0909\n",
      "Epoch 5 Batch 5 Loss 3.6331 Accuracy 0.0909\n",
      "Epoch 5 Batch 10 Loss 3.6330 Accuracy 0.0909\n",
      "Epoch 5 Batch 15 Loss 3.6330 Accuracy 0.0909\n",
      "Epoch 5 Batch 20 Loss 3.6330 Accuracy 0.0909\n",
      "Epoch 5 Batch 25 Loss 3.6346 Accuracy 0.0909\n",
      "Epoch 5 Batch 30 Loss 3.6359 Accuracy 0.0909\n",
      "Epoch 5 Batch 35 Loss 3.6362 Accuracy 0.0909\n",
      "Epoch 5 Batch 40 Loss 3.6361 Accuracy 0.0909\n",
      "Epoch 5 Batch 45 Loss 3.6359 Accuracy 0.0909\n",
      "Epoch 5 Batch 50 Loss 3.6357 Accuracy 0.0909\n",
      "Epoch 5 Batch 55 Loss 3.6356 Accuracy 0.0909\n",
      "Epoch 5 Batch 60 Loss 3.6354 Accuracy 0.0909\n",
      "Epoch 5 Batch 65 Loss 3.6352 Accuracy 0.0909\n",
      "Epoch 5 Batch 70 Loss 3.6351 Accuracy 0.0909\n",
      "Epoch 5 Batch 75 Loss 3.6349 Accuracy 0.0909\n",
      "Epoch 5 Batch 80 Loss 3.6348 Accuracy 0.0909\n",
      "Epoch 5 Batch 85 Loss 3.6349 Accuracy 0.0909\n",
      "Epoch 5 Batch 90 Loss 3.6349 Accuracy 0.0909\n",
      "Epoch 5 Loss 3.6349 Accuracy 0.0909\n",
      "Time taken for 1 epoch: 14.16 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    for (batch, (sentence_embeddings1, meetings1, summary1)) in enumerate(dataset):\n",
    "\n",
    "        train_step(sentence_embeddings1, meetings1, summary1, turns[batch])\n",
    "        \n",
    "        if batch % 5 == 0 : \n",
    "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "\n",
    "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "    print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb691c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
